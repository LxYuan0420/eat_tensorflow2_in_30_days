{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-2 Example: Modeling Procedure for Images.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCB6G1vEo9NM9ASABSM0v4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LxYuan0420/eat_tensorflow2_in_30_days/blob/master/notebooks/1_2_Example_Modeling_Procedure_for_Images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJkXmQZPo4KG",
        "outputId": "2e1e521b-97e7-4dd7-8463-d060e3c30675"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibob_TX2p5i2",
        "outputId": "5bd72f32-245f-4d4d-bbcc-b531fee73423"
      },
      "source": [
        "%cd /gdrive/MyDrive/Colab Notebooks/git/eat_tensorflow2_in_30_days/notebooks"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/Colab Notebooks/git/eat_tensorflow2_in_30_days/notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QchU0WOApF58"
      },
      "source": [
        "**1-2 Example: Modeling Procedure for Images**\r\n",
        "\r\n",
        "1. Data Preparation\r\n",
        "\r\n",
        "The cifar2 dataset is a sub-set of cifar10, which only contains two classes: airplane and automobile.\r\n",
        "\r\n",
        "Each class contains 5000 images for training and 1000 images for testing.\r\n",
        "\r\n",
        "The goal for this task is to train a model to classify images as airplane or automobile.\r\n",
        "\r\n",
        "The files of cifar2 are organized as below:\r\n",
        "\r\n",
        "`cifar2_datasets/train/0_airplane/*.jpg`\r\n",
        "\r\n",
        "`cifar2_datasets/train/1_automobile/*.jpg`\r\n",
        "\r\n",
        "`cifar2_datasets/test/0_airplane/*.jpg`\r\n",
        "\r\n",
        "`cifar2_datasets/test/1_automobile/*.jpg`\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "There are two ways of image preparation in TensorFlow.\r\n",
        "\r\n",
        "The first one is constructing the image data generator using ImageDataGenerator in tf.keras.\r\n",
        "\r\n",
        "The second one is constructing data pipeline using tf.data.Dataset and several methods in tf.image\r\n",
        "\r\n",
        "The former is simpler and is demonstrated in this article (in Chinese).\r\n",
        "\r\n",
        "The latter is the original method of TensorFlow, which is more flexible with possible better performance with proper usage.\r\n",
        "\r\n",
        "\r\n",
        "Below is the introduction to the second method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB6KcZmvptwz"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import datasets, layers, models\r\n",
        "\r\n",
        "BATCH_SIZE=100\r\n",
        "\r\n",
        "def load_image(img_path, size=(32,32)):\r\n",
        "    label = tf.constant(1, tf.int8) if tf.strings.regex_full_match(img_path, \".*automobile.*\") else tf.constant(0, tf.int8)\r\n",
        "    img = tf.io.read_file(img_path)\r\n",
        "    img = tf.io.decode_jpeg(img)\r\n",
        "    img = tf.image.resize(img, size) / 255.0\r\n",
        "\r\n",
        "    return (img, label)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95cVZ0Dpp90h"
      },
      "source": [
        "# sample output of Dataset.list_file(\"../filename/..\")\r\n",
        "# [b'../data/cifar2/train/automobile/4004.jpg']\r\n",
        "# so it is just a file path\r\n",
        "\r\n",
        "\r\n",
        "#Parellel pre-processing using num_parellel_calss and caching data with prefetch function to improve the performance\r\n",
        "ds_train = tf.data.Dataset.list_files(\"../data/cifar2/train/*/*.jpg\") \\\r\n",
        "            .map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\r\n",
        "            .shuffle(buffer_size=1000).batch(BATCH_SIZE) \\\r\n",
        "            .prefetch(tf.data.experimental.AUTOTUNE) \r\n",
        "\r\n",
        "ds_test = tf.data.Dataset.list_files(\"../data/cifar2/test/*/*.jpg\") \\\r\n",
        "            .map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\r\n",
        "            .batch(BATCH_SIZE) \\\r\n",
        "            .prefetch(tf.data.experimental.AUTOTUNE) "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfmf9d_BtN5u"
      },
      "source": [
        "%matplotlib inline\r\n",
        "%config InlineBackend.figure_format = 'svg'\r\n",
        "\r\n",
        "#Checking part of the samples\r\n",
        "from matplotlib import pyplot as plt \r\n",
        "\r\n",
        "plt.figure(figsize=(8,8)) \r\n",
        "for i,(img,label) in enumerate(ds_train.unbatch().take(9)):\r\n",
        "    ax=plt.subplot(3,3,i+1)\r\n",
        "    ax.imshow(img.numpy())\r\n",
        "    ax.set_title(\"label = %d\"%label)\r\n",
        "    ax.set_xticks([])\r\n",
        "    ax.set_yticks([]) \r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L36GfNn2szgu"
      },
      "source": [
        "for x, y in ds_train.take(1):\r\n",
        "    print(x.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr0wJoeHxVQu"
      },
      "source": [
        "**2. Model Definition**\r\n",
        "\r\n",
        "Usually there are three ways of modeling using APIs of Keras: sequential modeling using Sequential() function, arbitrary modeling using functional API, and customized modeling by inheriting base class Model.\r\n",
        "\r\n",
        "Here we use API functions for modeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB4de0ASxbdj"
      },
      "source": [
        "def img_classifier():\r\n",
        "    inputs = tf.keras.Input(shape=(32, 32, 3))\r\n",
        "    x = tf.keras.layers.Conv2D(32, kernel_size=(3,3))(inputs)\r\n",
        "    x = tf.keras.layers.MaxPool2D()(x)\r\n",
        "    x = tf.keras.layers.Conv2D(64, kernel_size=(5,5))(x)\r\n",
        "    x = tf.keras.layers.MaxPool2D()(x)\r\n",
        "    x = tf.keras.layers.Dropout(0.1)(x)\r\n",
        "    x = tf.keras.layers.Flatten()(x)\r\n",
        "    x = tf.keras.layers.Dense(32, activation='relu')(x)\r\n",
        "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\r\n",
        "\r\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\r\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAJoifvYzLMn",
        "outputId": "d2393624-fbb1-478e-a088-7f04f32b04c7"
      },
      "source": [
        "model = img_classifier()\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                51232     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 103,425\n",
            "Trainable params: 103,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni5xykSAzUds"
      },
      "source": [
        "**3. Model Training**\r\n",
        "\r\n",
        "There are three usual ways for model training: use internal function fit, use internal function train_on_batch, and customized training loop. Here we introduce the simplist way: using internal function fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFpg8dPw0ApL"
      },
      "source": [
        "import datetime\r\n",
        "import os\r\n",
        "\r\n",
        "stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "logdir = os.path.join('data', 'autograph', stamp)\r\n",
        "\r\n",
        "## We recommend using pathlib under Python3\r\n",
        "# from pathlib import Path\r\n",
        "# stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "# logdir = str(Path('../data/autograph/' + stamp))\r\n",
        "\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\r\n",
        "\r\n",
        "\r\n",
        "model.compile(\r\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\r\n",
        "    optimizer=tf.keras.optimizers.Adam(),\r\n",
        "    metrics=['accuracy']\r\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7IUctPa0db_"
      },
      "source": [
        "history = model.fit(ds_train,\r\n",
        "                    epochs=1,\r\n",
        "                    validation_data=ds_test,\r\n",
        "                    callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uhj1alw0sx8"
      },
      "source": [
        "**4. Model Evaluation**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ci6zHlH03WU"
      },
      "source": [
        "%load_ext tensorboard\r\n",
        "\r\n",
        "from tensorboard import notebook\r\n",
        "notebook.list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz9wmbCm09iF"
      },
      "source": [
        "notebook.start(\"--logdir ../data/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-_t7de32_cU"
      },
      "source": [
        "import pandas as pd \r\n",
        "dfhistory = pd.DataFrame(history.history)\r\n",
        "dfhistory.index = range(1,len(dfhistory) + 1)\r\n",
        "dfhistory.index.name = 'epoch'\r\n",
        "\r\n",
        "dfhistory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coiHApEX3BYK"
      },
      "source": [
        "%matplotlib inline\r\n",
        "%config InlineBackend.figure_format = 'svg'\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "def plot_metric(history, metric):\r\n",
        "    train_metrics = history.history[metric]\r\n",
        "    val_metrics = history.history['val_'+metric]\r\n",
        "    epochs = range(1, len(train_metrics) + 1)\r\n",
        "    plt.plot(epochs, train_metrics, 'bo--')\r\n",
        "    plt.plot(epochs, val_metrics, 'ro-')\r\n",
        "    plt.title('Training and validation '+ metric)\r\n",
        "    plt.xlabel(\"Epochs\")\r\n",
        "    plt.ylabel(metric)\r\n",
        "    plt.legend([\"train_\"+metric, 'val_'+metric])\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEwvOQBt3CaG"
      },
      "source": [
        "plot_metric(history,\"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tjKZlbq3En-"
      },
      "source": [
        "plot_metric(history,\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yznMi5GY3jlZ"
      },
      "source": [
        "#Evaluating data using model.evaluate function\r\n",
        "val_loss,val_accuracy = model.evaluate(ds_test,workers=4)\r\n",
        "print(val_loss,val_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9-lu4cc3nEt"
      },
      "source": [
        "**Model Saving**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wabw6RrD3oss"
      },
      "source": [
        "# Saving the weights, this way only save the tensors of the weights\r\n",
        "model.save_weights('../model_weights/tf_model_weights.ckpt',save_format = \"tf\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6-5 Model Training Using TPU.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNBTaYG1VMAY/DRqkBUdbdm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LxYuan0420/eat_tensorflow2_in_30_days/blob/master/notebooks/6_5_Model_Training_Using_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30mzHPlJ-isT"
      },
      "source": [
        "It only requires six additional lines of code when training your model using TPU on Google Colab.\r\n",
        "\r\n",
        "In Colab notebook, choose TPU in Edit -> Notebook Settings -> Hardware Accelerator.\r\n",
        "\r\n",
        "Note: the following code only executes on Colab.\r\n",
        "\r\n",
        "You may use the following link for testing (tf_TPU, in Chinese)\r\n",
        "\r\n",
        "https://colab.research.google.com/drive/1XCIhATyE1R7lq6uwFlYlRsUr5d9_-r1s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "41_1dYpE-o4H",
        "outputId": "4357a2f8-2331-4d49-b845-95e547d41eae"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGPcQK3l_GrH"
      },
      "source": [
        "from tensorflow.keras import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYvRl-e6_1FS"
      },
      "source": [
        "**1. Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_equEFNJ_67t",
        "outputId": "0a84ee9f-f753-4041-9dfe-76ba5e861f27"
      },
      "source": [
        "MAX_LEN = 300\r\n",
        "BATCH_SIZE = 8 #reduce from 32 to 8, got error: Unable to parse tensor proto\r\n",
        "\r\n",
        "(x_train, y_train), (x_test, y_test) = datasets.reuters.load_data()\r\n",
        "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=MAX_LEN)\r\n",
        "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=MAX_LEN)\r\n",
        "\r\n",
        "MAX_WORDS = x_train.max() + 1\r\n",
        "CAT_NUM = y_train.max() + 1\r\n",
        "\r\n",
        "ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE).cache()\r\n",
        "ds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)).shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE).cache()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPnTI3cOAlNt"
      },
      "source": [
        "def create_model():\r\n",
        "\r\n",
        "    model = models.Sequential()\r\n",
        "    model.add(layers.Embedding(MAX_WORDS, 7, input_length=MAX_LEN))\r\n",
        "    model.add(layers.Conv1D(filters=64, kernel_size=5, activation='relu'))\r\n",
        "    model.add(layers.MaxPool1D())\r\n",
        "    model.add(layers.Conv1D(filters=32, kernel_size=3, activation='relu'))\r\n",
        "    model.add(layers.MaxPool1D())\r\n",
        "    model.add(layers.Flatten())\r\n",
        "    model.add(layers.Dense(CAT_NUM, activation='softmax'))\r\n",
        "\r\n",
        "    return model\r\n",
        "\r\n",
        "def compile_model(model):\r\n",
        "    model.compile(\r\n",
        "        loss = losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "        optimizer = optimizers.Nadam(),\r\n",
        "        metrics = [metrics.SparseCategoricalAccuracy(), metrics.SparseTopKCategoricalAccuracy()]\r\n",
        "    )\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WH1vyzhBTCh"
      },
      "source": [
        "**3. Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpaR5O2RBWjU",
        "outputId": "e75d9137-fce6-4169-9476-d7ecb2eb46d2"
      },
      "source": [
        "# the 6 additional lines of code\r\n",
        "import os\r\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"grpc://\" + os.environ['COLAB_TPU_ADDR'])\r\n",
        "tf.config.experimental_connect_to_cluster(resolver)\r\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\r\n",
        "\r\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\r\n",
        "with strategy.scope():\r\n",
        "    model = create_model()\r\n",
        "    model.summary()\r\n",
        "    model = compile_model(model)\r\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.105.197.218:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.105.197.218:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.105.197.218:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.105.197.218:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 300, 7)            216874    \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 296, 64)           2304      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 148, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 146, 32)           6176      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 73, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 2336)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 46)                107502    \n",
            "=================================================================\n",
            "Total params: 332,856\n",
            "Trainable params: 332,856\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS6FZVJABzhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e001f526-7ea3-4d32-8de8-7bfbf6c559d8"
      },
      "source": [
        "history = model.fit(ds_train, validation_data=ds_test, epochs=10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1123/1123 [==============================] - 34s 26ms/step - loss: 2.1022 - sparse_categorical_accuracy: 0.4564 - sparse_top_k_categorical_accuracy: 0.7294 - val_loss: 1.5396 - val_sparse_categorical_accuracy: 0.6113 - val_sparse_top_k_categorical_accuracy: 0.7760\n",
            "Epoch 2/10\n",
            "1123/1123 [==============================] - 28s 25ms/step - loss: 1.3959 - sparse_categorical_accuracy: 0.6370 - sparse_top_k_categorical_accuracy: 0.8020 - val_loss: 1.4756 - val_sparse_categorical_accuracy: 0.6402 - val_sparse_top_k_categorical_accuracy: 0.8085\n",
            "Epoch 3/10\n",
            "1123/1123 [==============================] - 28s 25ms/step - loss: 1.0306 - sparse_categorical_accuracy: 0.7242 - sparse_top_k_categorical_accuracy: 0.8867 - val_loss: 1.6521 - val_sparse_categorical_accuracy: 0.6349 - val_sparse_top_k_categorical_accuracy: 0.8094\n",
            "Epoch 4/10\n",
            "1123/1123 [==============================] - 28s 25ms/step - loss: 0.6970 - sparse_categorical_accuracy: 0.8202 - sparse_top_k_categorical_accuracy: 0.9459 - val_loss: 2.0263 - val_sparse_categorical_accuracy: 0.6198 - val_sparse_top_k_categorical_accuracy: 0.8148\n",
            "Epoch 5/10\n",
            "1123/1123 [==============================] - 28s 25ms/step - loss: 0.4731 - sparse_categorical_accuracy: 0.8822 - sparse_top_k_categorical_accuracy: 0.9771 - val_loss: 2.3113 - val_sparse_categorical_accuracy: 0.6175 - val_sparse_top_k_categorical_accuracy: 0.8143\n",
            "Epoch 6/10\n",
            "1123/1123 [==============================] - 29s 25ms/step - loss: 0.3417 - sparse_categorical_accuracy: 0.9156 - sparse_top_k_categorical_accuracy: 0.9891 - val_loss: 2.6085 - val_sparse_categorical_accuracy: 0.6193 - val_sparse_top_k_categorical_accuracy: 0.8117\n",
            "Epoch 7/10\n",
            "1123/1123 [==============================] - 28s 25ms/step - loss: 0.2717 - sparse_categorical_accuracy: 0.9316 - sparse_top_k_categorical_accuracy: 0.9934 - val_loss: 2.9208 - val_sparse_categorical_accuracy: 0.6122 - val_sparse_top_k_categorical_accuracy: 0.8059\n",
            "Epoch 8/10\n",
            "1123/1123 [==============================] - 29s 26ms/step - loss: 0.2260 - sparse_categorical_accuracy: 0.9404 - sparse_top_k_categorical_accuracy: 0.9958 - val_loss: 3.2647 - val_sparse_categorical_accuracy: 0.6055 - val_sparse_top_k_categorical_accuracy: 0.8019\n",
            "Epoch 9/10\n",
            "1123/1123 [==============================] - 28s 25ms/step - loss: 0.1976 - sparse_categorical_accuracy: 0.9452 - sparse_top_k_categorical_accuracy: 0.9977 - val_loss: 3.5498 - val_sparse_categorical_accuracy: 0.5975 - val_sparse_top_k_categorical_accuracy: 0.8028\n",
            "Epoch 10/10\n",
            "1123/1123 [==============================] - 29s 26ms/step - loss: 0.1740 - sparse_categorical_accuracy: 0.9505 - sparse_top_k_categorical_accuracy: 0.9981 - val_loss: 3.8593 - val_sparse_categorical_accuracy: 0.5908 - val_sparse_top_k_categorical_accuracy: 0.7983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2l5rVhHICJS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
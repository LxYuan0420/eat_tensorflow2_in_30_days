{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6-1 Three Ways of Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPtjZytV0VZAZ+wPxHrHml",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LxYuan0420/eat_tensorflow2_in_30_days/blob/master/notebooks/6_1_Three_Ways_of_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX_1zFd1SnMa"
      },
      "source": [
        "**6-1 Three Ways of Modeling**\r\n",
        "\r\n",
        "There are three ways of modeling: using Sequential to construct model with the order of layers, using functional APIs to construct model with arbitrary structure, using child class inheriting from the base class Model.\r\n",
        "\r\n",
        "For the models with sequenced structure, Sequential method should be given the highest priority.\r\n",
        "\r\n",
        "For the models with nonsequenced structures such as multiple input/output, shared weights, or residual connections, modeling with functional API is recommended.\r\n",
        "\r\n",
        "Modeling through child class of Model should be AVOIDED unless with special requirements. This method is flexible, but also fallible.\r\n",
        "\r\n",
        "Here are the examples of modeling using the three above-mentioned methods to classify IMDB movie reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hv35vRAS2sK",
        "outputId": "d66fd409-b9f1-4d33-9a8b-080e089b8def"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP3qYdJxS2sL",
        "outputId": "d713eabf-ad4d-4128-a4e5-2f926cbb5e17"
      },
      "source": [
        "%cd \"/gdrive/MyDrive/Colab Notebooks/git/eat_tensorflow2_in_30_days/notebooks\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/Colab Notebooks/git/eat_tensorflow2_in_30_days/notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc2JKRF4Squ_"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "from tqdm import tqdm\r\n",
        "from tensorflow.keras import *"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwt7matSSxaw"
      },
      "source": [
        "train_token_path = \"../data/imdb/train_token.csv\"\r\n",
        "test_token_path = \"../data/imdb/test_token.csv\"\r\n",
        "\r\n",
        "MAX_WORDS = 10000 # We will only consider the top 10,000 words in the dataset\r\n",
        "MAX_LEN = 200\r\n",
        "BATCH_SIZE = 20\r\n",
        "\r\n",
        "# Constructing data pipeline\r\n",
        "def parse_line(line):\r\n",
        "    t = tf.strings.split(line,\"\\t\")\r\n",
        "    label = tf.reshape(tf.cast(tf.strings.to_number(t[0]),tf.int32),(-1,))\r\n",
        "    features = tf.cast(tf.strings.to_number(tf.strings.split(t[1],\" \")),tf.int32)\r\n",
        "    return (features,label)\r\n",
        "\r\n",
        "ds_train=  tf.data.TextLineDataset(filenames = [train_token_path]) \\\r\n",
        "   .map(parse_line,num_parallel_calls = tf.data.experimental.AUTOTUNE) \\\r\n",
        "   .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\r\n",
        "   .prefetch(tf.data.experimental.AUTOTUNE)\r\n",
        "\r\n",
        "ds_test = tf.data.TextLineDataset(filenames=[test_token_path]) \\\r\n",
        "    .map(parse_line, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\r\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf0o6bp-UdD0"
      },
      "source": [
        "**1. Modeling using `Sequential`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R786oDxBVStd",
        "outputId": "f198364b-4ebc-4c89-a5b3-5047622b9489"
      },
      "source": [
        "model = models.Sequential()\r\n",
        "\r\n",
        "model.add(layers.Embedding(MAX_WORDS, 7, input_length=MAX_LEN))\r\n",
        "model.add(layers.Conv1D(filters=64, kernel_size=5, activation='relu'))\r\n",
        "model.add(layers.MaxPool1D(2))\r\n",
        "model.add(layers.Conv1D(filters=32, kernel_size=3, activation='relu'))\r\n",
        "model.add(layers.MaxPool1D(2))\r\n",
        "model.add(layers.Flatten())\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(\r\n",
        "    optimizer='Nadam',\r\n",
        "    loss='binary_crossentropy',\r\n",
        "    metrics = [\"accuracy\", \"AUC\"]\r\n",
        ")\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 200, 7)            70000     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 196, 64)           2304      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 98, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 96, 32)            6176      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 48, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1536)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 1537      \n",
            "=================================================================\n",
            "Total params: 80,017\n",
            "Trainable params: 80,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhtRVN4YYimH"
      },
      "source": [
        "import datetime\r\n",
        "\r\n",
        "baselogger = callbacks.BaseLogger(stateful_metrics=[\"AUC\"])\r\n",
        "logdir = \"../data/keras_model\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\r\n",
        "\r\n",
        "history = model.fit(ds_train, validation_data=ds_test,\r\n",
        "                    epochs=6,\r\n",
        "                    callbacks=[baselogger, tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TISN4ZuKbLT_"
      },
      "source": [
        "**2. Modeling Using Functional API**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S-o5F-bbaAJ",
        "outputId": "7686c05b-b4f4-4df6-c184-fa0ff9a77bcc"
      },
      "source": [
        "\r\n",
        "inputs = layers.Input(shape=[MAX_LEN])\r\n",
        "x  = layers.Embedding(MAX_WORDS,7)(inputs)\r\n",
        "\r\n",
        "branch1 = layers.SeparableConv1D(64,3,activation=\"relu\")(x)\r\n",
        "branch1 = layers.MaxPool1D(3)(branch1)\r\n",
        "branch1 = layers.SeparableConv1D(32,3,activation=\"relu\")(branch1)\r\n",
        "branch1 = layers.GlobalMaxPool1D()(branch1)\r\n",
        "\r\n",
        "branch2 = layers.SeparableConv1D(64,5,activation=\"relu\")(x)\r\n",
        "branch2 = layers.MaxPool1D(5)(branch2)\r\n",
        "branch2 = layers.SeparableConv1D(32,5,activation=\"relu\")(branch2)\r\n",
        "branch2 = layers.GlobalMaxPool1D()(branch2)\r\n",
        "\r\n",
        "branch3 = layers.SeparableConv1D(64,7,activation=\"relu\")(x)\r\n",
        "branch3 = layers.MaxPool1D(7)(branch3)\r\n",
        "branch3 = layers.SeparableConv1D(32,7,activation=\"relu\")(branch3)\r\n",
        "branch3 = layers.GlobalMaxPool1D()(branch3)\r\n",
        "\r\n",
        "concat = layers.Concatenate()([branch1,branch2,branch3])\r\n",
        "outputs = layers.Dense(1,activation = \"sigmoid\")(concat)\r\n",
        "\r\n",
        "model = models.Model(inputs = inputs,outputs = outputs)\r\n",
        "\r\n",
        "model.compile(optimizer='Nadam',\r\n",
        "            loss='binary_crossentropy',\r\n",
        "            metrics=['accuracy',\"AUC\"])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 200, 7)       70000       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d (SeparableConv (None, 198, 64)      533         embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d_2 (SeparableCo (None, 196, 64)      547         embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d_4 (SeparableCo (None, 194, 64)      561         embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 66, 64)       0           separable_conv1d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1D)  (None, 39, 64)       0           separable_conv1d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1D)  (None, 27, 64)       0           separable_conv1d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d_1 (SeparableCo (None, 64, 32)       2272        max_pooling1d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d_3 (SeparableCo (None, 35, 32)       2400        max_pooling1d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv1d_5 (SeparableCo (None, 21, 32)       2528        max_pooling1d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 32)           0           separable_conv1d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 32)           0           separable_conv1d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_2 (GlobalM (None, 32)           0           separable_conv1d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 96)           0           global_max_pooling1d[0][0]       \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "                                                                 global_max_pooling1d_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            97          concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 78,938\n",
            "Trainable params: 78,938\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZJslHPWbbvS"
      },
      "source": [
        "**3. Customized Modeling Using Child Class of `Model`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAMESgeWbrAp"
      },
      "source": [
        "class ResBlock(layers.Layer):\r\n",
        "    def __init__(self, kernel_size, **kwargs):\r\n",
        "        super(ResBlock, self).__init__()\r\n",
        "        self.kernel_size = kernel_size\r\n",
        "\r\n",
        "    def build(self, input_shape):\r\n",
        "        self.conv1 = layers.Conv1D(filters=64, kernel_size=self.kernel_size,\r\n",
        "                                   activation='relu', padding=\"same\")\r\n",
        "        self.conv2 = layers.Conv1D(filters=32, kernel_size=self.kernel_size,\r\n",
        "                                   activation='relu', padding=\"same\")\r\n",
        "        self.conv3 = layers.Conv1D(filters=input_shape[-1],\r\n",
        "                                   kernel_size=self.kernel_size,\r\n",
        "                                   activation='relu',\r\n",
        "                                   padding='same')\r\n",
        "        self.maxpool = layers.MaxPool1D()\r\n",
        "        super(ResBlock, self).build(input_shape)\r\n",
        "    \r\n",
        "    def call(self, inputs):\r\n",
        "        x = self.conv1(inputs)\r\n",
        "        x = self.conv2(x)\r\n",
        "        x = self.conv3(x)\r\n",
        "        x = layers.Add()([inputs, x])\r\n",
        "        x = self.maxpool(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "    def get_config(self):\r\n",
        "        config = super(ResBlock, self).get_config()\r\n",
        "        config.update({\"kernel_size\": self.kernel_size})\r\n",
        "        return config"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3RA0xadc4-8",
        "outputId": "5f695521-be02-4051-96a6-ae9dfca4508f"
      },
      "source": [
        "resblock = ResBlock(kernel_size=3)\r\n",
        "resblock.build(input_shape=(None, 200, 7))\r\n",
        "resblock.compute_output_shape(input_shape=(None, 200, 7))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 100, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUf983HhdEvg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
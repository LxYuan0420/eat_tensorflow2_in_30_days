{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-2 Three Types of Graph.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNe7ZR80rabHx8GYNBMsslw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LxYuan0420/eat_tensorflow2_in_30_days/blob/master/notebooks/2_2_Three_Types_of_Graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr62r6qe_Vkf"
      },
      "source": [
        "There are three types of graph: static, dynamic, and Autograph.\r\n",
        "\r\n",
        "TensorFlow 1.X used static graph, which firstly creating the graph by various operators and then open a Session to execute the graph.\r\n",
        "\r\n",
        "For TensorFlow 2.X, dynamic graph is used. The operator will be added to the invisible default graph and executed instantaneously after its usage; there is no need to create a Session.\r\n",
        "\r\n",
        "Using dynamic graph (i.e. Eager Execution) is convenient for debugging, as it improves performance of TensorFlow code just as original Python code, with possibilities of log output and flow control, etc.\r\n",
        "\r\n",
        "The drawback of dynamic graph is a relatively lower execution efficiency comparing to static graph. This is because multiple times of communication between the Python thread and the C++ thread of TensorFlow Kernel is required for dynamic graph, while the static graph is executed almost all on the TensorFlow kernel using C++ code with higher efficiency. What's more, the static graph optimizes the computation, reducing the steps that are not relevant to the result.\r\n",
        "\r\n",
        "It is possible to use the decorator `@tf.function` to construct code by converting normal Python function to TensorFlow graph. Executing this function is identical to executing Session in TensorFlow 1.X. This method, which uses decorator @tf.function to create static graph, is called Autograph.\r\n",
        "\r\n",
        "**1. Introduction to Graph**\r\n",
        "\r\n",
        "The graph consists of nodes and edges.\r\n",
        "\r\n",
        "The node represent operator, while the edge represents the dependencies between the operators.\r\n",
        "\r\n",
        "The solid edge (line) represents the dependency with data (tensor) transmission.\r\n",
        "\r\n",
        "The dotted edge (line) represents the dependency of control, i.e. the order of execution.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJGN8QXz_gxm"
      },
      "source": [
        "**2. The Static Graph**\r\n",
        "\r\n",
        "In TensorFlow 1.X, the static graph is impelmented in two steps: defining the graph and executing it in Session.\r\n",
        "\r\n",
        "Example of Static Graph in TensorFlow 1.X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXPNOGFm_wtB"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "#Defining the graph\r\n",
        "g = tf.Graph()\r\n",
        "with g.as_default():\r\n",
        "    # The object of the placeholder will be designated during the execution of the Session\r\n",
        "    x = tf.placeholder(name='x', shape=[], dtype=tf.string)\r\n",
        "    y = tf.placeholder(name='y', shape=[], dtype=tf.string)\r\n",
        "    z = tf.strings.join([x,y], name='join', separator=' ')\r\n",
        "\r\n",
        "\r\n",
        "#Executing the graph\r\n",
        "with tf.Session(graph=g) as sess:\r\n",
        "    print(sess.run(fetches=z, feed_dict={x:'hello', y:\"world\"}))\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGkbryseAW4T"
      },
      "source": [
        "**The Static Graph in TensorFlow2.0 as a memorial**\r\n",
        "\r\n",
        "In order to be compatible to the old versions, TensorFlow 2.X supports the TensorFlow 1.X styled static graph in the sub-module `tf.compat.v1`. \r\n",
        "\r\n",
        "This is just for memorial and we do NOT recommend this way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBvki9FWAmP5",
        "outputId": "a97b6c79-0ace-4ba4-bebb-8052a6200850"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "g = tf.compat.v1.Graph()\r\n",
        "with g.as_default():\r\n",
        "    x = tf.compat.v1.placeholder(name = 'x', shape=[], dtype=tf.string)\r\n",
        "    y = tf.compat.v1.placeholder(name = 'y', shape=[], dtype=tf.string)\r\n",
        "    z = tf.strings.join([x,y], name = 'join', separator=' ')\r\n",
        "    \r\n",
        "\r\n",
        "with tf.compat.v1.Session(graph=g) as sess:\r\n",
        "    results = sess.run(fetches = z, feed_dict={x: \"hello\", y: \"world\"})\r\n",
        "    print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'hello world'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt2QyOLuCE3A"
      },
      "source": [
        "**3. The Dynamic Graph**\r\n",
        "\r\n",
        "TensorFlow 2.X uses the dynamic graph and Autograph.\r\n",
        "\r\n",
        "In TensorFlow 1.X, the static graph is impelmented in two steps: defining the graph and executing it in Session.\r\n",
        "\r\n",
        "However, the definition and execution is no more distinguishable for dynamic graph. It executes immediatly after definition and that's the reason why it is called \"Eager Excution\".\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11EyUx2wCKMp",
        "outputId": "15ac9f92-602e-4d95-b168-cabe97e71802"
      },
      "source": [
        "x = tf.constant(\"hello\")\r\n",
        "y = tf.constant(\"world\")\r\n",
        "z = tf.strings.join([x, y], separator=' ') \r\n",
        "\r\n",
        "tf.print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello world\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XVf_UCIBO4T",
        "outputId": "438a7d3b-d0e6-4ef1-c476-a07bf9401198"
      },
      "source": [
        "# The input/output of the dynamic graph could be packaged as a function\r\n",
        "\r\n",
        "def strjoin(x, y):\r\n",
        "    z = tf.strings.join([x, y], name='join', separator=' ')\r\n",
        "    tf.print(z)\r\n",
        "    return z\r\n",
        "\r\n",
        "result = strjoin(tf.constant(\"hello\"), tf.constant(\"world\"))\r\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello world\n",
            "tf.Tensor(b'hello world', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hdaPD3aBsXb"
      },
      "source": [
        "**4. Autograph in TensorFlow 2.X**\r\n",
        "\r\n",
        "\r\n",
        "The dynamic graph has a relatively lower efficiency in execution.\r\n",
        "\r\n",
        "We can use the decorator @tf.function to convert the original Python functions into the static graph as TensorFlow 1.Xã€‚\r\n",
        "\r\n",
        "In TensorFlow 1.X, the static graph is impelmented in two steps: defining the graph and executing it in Session.\r\n",
        "\r\n",
        "In TensorFlow 2.X, the two steps for Autographs are: defining the function with a decorator '@tf.function' and calling this function.\r\n",
        "\r\n",
        "The is no need to use Session, so the syntax is as smooth as that of original Python.\r\n",
        "\r\n",
        "In reality, we will debug with the dynamic graph, and shift to Autograph using decorator @tf.function for the code requires higher efficiency of execution.\r\n",
        "\r\n",
        "There are certain rules of implementing @tf.function, which will be introduced in the following chapters.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udqwId43Bsap",
        "outputId": "0327b776-df8c-4add-fbfa-601cba282d4e"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "# Use Autograph to construct the static graph\r\n",
        "\r\n",
        "@tf.function\r\n",
        "def strjoin(x, y):\r\n",
        "    z = tf.strings.join([x, y], separator=' ')\r\n",
        "    tf.print(z)\r\n",
        "    return z\r\n",
        "\r\n",
        "result = strjoin(tf.constant('Hello'), tf.constant(\"World\"))\r\n",
        "\r\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello World\n",
            "tf.Tensor(b'Hello World', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D1EbWmMBsdk"
      },
      "source": [
        "import datetime\r\n",
        "import os\r\n",
        "\r\n",
        "stamp = datetime.datetime.now().strftime(\"%Y%m%d - %H%M%S\")\r\n",
        "logdir = os.path.join('data', 'autograph', stamp)\r\n",
        "\r\n",
        "# We recommend using pathlib under Python3\r\n",
        "# from pathlib import Path\r\n",
        "# stamp = datetime.datatime.now().strftime(\"%Y%m%d - %H%M%S\")\r\n",
        "# logdir = str(Path('../data/autograph'+ stamp))\r\n",
        "\r\n",
        "writer = tf.summary.create_file_writer(logdir)\r\n",
        "\r\n",
        "# start tracing on Autograph\r\n",
        "tf.summary.trace_on(graph=True, profiler=True)\r\n",
        "\r\n",
        "# Execute Autograph\r\n",
        "result = strjoin(\"hello\", \"world\")\r\n",
        "\r\n",
        "# Write the graph info into the log\r\n",
        "with writer.as_default():\r\n",
        "    tf.summary.trace_export(\r\n",
        "        name = \"autograph\",\r\n",
        "        step=0,\r\n",
        "        profiler_outdir=logdir \r\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHtZsDeUBsgP"
      },
      "source": [
        "# Magic command to launch tensorboard in jupyter\r\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIBaEiSLBsl4"
      },
      "source": [
        "# Launch tensorboard\r\n",
        "%tensorboard --logdir ../data/autograph/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}